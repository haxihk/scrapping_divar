import requests
import time

# URL API Ø¯ÛŒÙˆØ§Ø±
url = "https://api.divar.ir/v8/postlist/w/search"

# Ù‡Ø¯Ø±Ù‡Ø§ÛŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¨Ù„Ø§Ú© Ø´Ø¯Ù†
headers = {
    "Content-Type": "application/json",
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
}

# ØªØ¹Ø¯Ø§Ø¯ Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ÛŒÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒÙ… Ø¯Ø±ÛŒØ§ÙØª Ú©Ù†ÛŒÙ…
MAX_TOKENS = 2000
RETRY_LIMIT = 5  # ØªØ¹Ø¯Ø§Ø¯ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯ Ø¯Ø± ØµÙˆØ±Øª Ø®Ø·Ø§
DELAY_BETWEEN_REQUESTS = 0.5  # Ú©Ø§Ù‡Ø´ ØªØ£Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª

# Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² `requests.Session()` Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª Ùˆ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ
session = requests.Session()
session.headers.update(headers)

list_of_tokens = []
last_post_date = None
count = 0
page = 1

while count < MAX_TOKENS:
    payload = {
        "city_ids": ["1"],
        "pagination_data": {
            "@type": "type.googleapis.com/post_list.PaginationData",
            "last_post_date": last_post_date if last_post_date else None,
            "page": page,
            "layer_page": 1
        },
        "disable_recommendation": False,
        "map_state": {"camera_info": {"bbox": {}}},
        "search_data": {
            "form_data": {
                "data": {
                    "category": {"str": {"value": "apartment-sell"}}
                }
            },
            "server_payload": {
                "@type": "type.googleapis.com/widgets.SearchData.ServerPayload",
                "additional_form_data": {
                    "data": {"sort": {"str": {"value": "sort_date"}}}
                }
            }
        }
    }

    # Ø­Ø°Ù `last_post_date` Ø¯Ø± Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø§ÙˆÙ„
    if last_post_date is None:
        del payload["pagination_data"]["last_post_date"]

    retries = 0
    while retries < RETRY_LIMIT:
        try:
            res = session.post(url, json=payload)
            res.raise_for_status()

            if res.status_code == 429:
                print("ğŸš« Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø²ÛŒØ§Ø¯ Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯Ù‡ØŒ Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù†ÛŒØ¯...")
                time.sleep(10)
                retries += 1
                continue

            data = res.json()
            last_post_date = data.get("last_post_date")
            page += 1  # Ø§ÙØ²Ø§ÛŒØ´ Ø´Ù…Ø§Ø±Ù‡ ØµÙØ­Ù‡

            # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡Ø± Ø¢Ú¯Ù‡ÛŒ Ø¯Ø± `list_widgets`
            for widget in data.get("list_widgets", []):
                try:
                    token = widget["data"]["action"]["payload"]["token"]
                    if token and token not in list_of_tokens:
                        list_of_tokens.append(token)
                        count += 1
                        print(f"âœ… {count}: {token}")
                except KeyError:
                    continue  # Ø±Ø¯ Ú©Ø±Ø¯Ù† Ø¢Ú¯Ù‡ÛŒâ€ŒÙ‡Ø§ÛŒ Ù†Ø§Ù…Ø¹ØªØ¨Ø±

            time.sleep(DELAY_BETWEEN_REQUESTS)  # Ú©Ø§Ù‡Ø´ ØªØ£Ø®ÛŒØ± Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª

            if not data.get("list_widgets"):
                print("ğŸš« Ø¯ÛŒÚ¯Ø± Ø¢Ú¯Ù‡ÛŒ Ø¬Ø¯ÛŒØ¯ÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.")
                break

            break  # Ø§Ú¯Ø± Ù…ÙˆÙÙ‚ Ø´Ø¯ØŒ Ø§Ø² Ø­Ù„Ù‚Ù‡ `retry` Ø®Ø§Ø±Ø¬ Ø´ÙˆØ¯

        except requests.exceptions.RequestException as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡: {e}")
            retries += 1
            time.sleep(3)  # Ø§Ù†ØªØ¸Ø§Ø± Ø¨Ø±Ø§ÛŒ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯

    if retries == RETRY_LIMIT:
        print("ğŸš¨ Ú†Ù†Ø¯ÛŒÙ† ØªÙ„Ø§Ø´ Ù†Ø§Ù…ÙˆÙÙ‚ØŒ ØªÙˆÙ‚Ù Ø¨Ø±Ù†Ø§Ù…Ù‡.")
        break

# Ø°Ø®ÛŒØ±Ù‡ ØªÙˆÚ©Ù†â€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ ÛŒÚ©Ø¬Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ Ø³Ø±Ø¹Øª
with open("tokens.txt", "w", encoding="utf-8") as txt_file:
    txt_file.write("\n".join(list_of_tokens))

print(f"\nâœ… ØªØ¹Ø¯Ø§Ø¯ {len(list_of_tokens)} ØªÙˆÚ©Ù† Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø± tokens.txt")
